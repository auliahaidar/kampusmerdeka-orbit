# -*- coding: utf-8 -*-
"""Copy of K-Means Clustering for Customer Segmentation

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1r23Tar3QoMKbQB8N92VeiHY_do273dEq

Pada studi kasus kali ini kita akan mencoba untuk men-clusterkan customer pada suatu mall. Berdasarkan 2 variabel yaitu pendapatan dan pengeluaran customer.

# **Import Library**
"""

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import matplotlib.pyplot as plt #Data Visualization
import seaborn as sns  #Python library for Vidualization

"""#**Read Data**"""

dataset = pd.read_csv('https://raw.githubusercontent.com/HafizahIlma/data/main/Mall_Customers.csv')
dataset.head(10)

#total rows and colums in the dataset
dataset.shape

dataset.info() # there are no missing values as all the columns has 200 entries properly

"""## Missing values computation"""

dataset.isnull().sum()

"""## Feature selection for the model

Pada studi kasus kali ini hanya menggunakan 2 variabel, yaitu: Annual income dan Spending Score
"""

#Mengambil hanya 2 fitur (Pendapatan Tahunan dan Skor Pengeluaran) dan Label tidak tersedia
X= dataset.iloc[:, [3,4]].values

"""## Membangun Model

Algoritma KMeans untuk menentukan jumlah cluster yang optimal , KMeans menggunakan Metode Elbow

"""

from sklearn.cluster import KMeans
wcss=[]

for i in range(1,11):
    kmeans = KMeans(n_clusters= i, init='k-means++', random_state=0)
    kmeans.fit(X)
    wcss.append(kmeans.inertia_)

"""# **Visualizing the ELBOW method to get the optimal value of K**"""

plt.plot(range(1,11), wcss)
plt.title('The Elbow Method')
plt.xlabel('no of clusters')
plt.ylabel('wcss')
plt.show()

#If you zoom out this curve then you will see that last elbow comes at k=5
#no matter what range we select ex- (1,21) also i will see the same behaviour but if we chose higher range it is little difficult to visualize the ELBOW
#that is why we usually prefer range (1,11)
##Finally we got that k=5

#Model Build
kmeansmodel = KMeans(n_clusters= 5, init='k-means++', random_state=0)
y_kmeans= kmeansmodel.fit_predict(X)

#For unsupervised learning we use "fit_predict()" wherein for supervised learning we use "fit_tranform()"
#y_kmeans is the final model . Now how and where we will deploy this model in production is depends on what tool we are using.
#This use case is very common and it is used in BFS industry(credit card) and retail for customer segmenattion.

"""## **Visualizing all the clusters**"""

plt.scatter(X[y_kmeans == 0, 0], X[y_kmeans == 0, 1], s = 100, c = 'red', label = 'Cluster 1')
plt.scatter(X[y_kmeans == 1, 0], X[y_kmeans == 1, 1], s = 100, c = 'blue', label = 'Cluster 2')
plt.scatter(X[y_kmeans == 2, 0], X[y_kmeans == 2, 1], s = 100, c = 'green', label = 'Cluster 3')
plt.scatter(X[y_kmeans == 3, 0], X[y_kmeans == 3, 1], s = 100, c = 'cyan', label = 'Cluster 4')
plt.scatter(X[y_kmeans == 4, 0], X[y_kmeans == 4, 1], s = 100, c = 'magenta', label = 'Cluster 5')
plt.title('Clusters of customers')
plt.xlabel('Annual Income (k$)')
plt.ylabel('Spending Score (1-100)')
plt.legend()
plt.show()

"""## **Model Interpretation**

*   Cluster 1 (Red Color): Penghasilan tinggi tetapi pengeluaran lebih sedikit
*   Cluster 2 (Blue Color): Rata-rata dalam hal penghasilan dan pengeluaran
*   Cluster 3 (Green Color): Penghasilan tinggi dan juga pengeluaran tinggi [SET TARGET]
*   Cluster 4 (Cyan Color): Penghasilan lebih sedikit tetapi pengeluaran lebih banyak
*   Cluster 5 (Magenta Color): Penghasilan lebih sedikit, pengeluaran lebih sedikit

Insight: dapat menempatkan Cluster 3 ke dalam beberapa sistem peringatan di mana email dapat dikirim kepada mereka setiap hari karena ini mudah untuk berkomunikasi. Sedangkan yang lain bisa kita atur seperti seminggu sekali atau sebulan sekali.
"""